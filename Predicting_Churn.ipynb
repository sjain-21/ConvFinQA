{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sjain-21/ConvFinQA/blob/main/Predicting_Churn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "scrolled": true,
        "id": "vKaSofEz2CPl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24648566-db7b-43ec-e5a1-62ac5e4c9ed0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DS4B_Sp24'...\n",
            "remote: Enumerating objects: 860, done.\u001b[K\n",
            "remote: Counting objects: 100% (262/262), done.\u001b[K\n",
            "remote: Compressing objects: 100% (144/144), done.\u001b[K\n",
            "remote: Total 860 (delta 122), reused 255 (delta 116), pack-reused 598\u001b[K\n",
            "Receiving objects: 100% (860/860), 159.30 MiB | 12.02 MiB/s, done.\n",
            "Resolving deltas: 100% (385/385), done.\n",
            "Updating files: 100% (146/146), done.\n",
            "/content/DS4B_Sp24/Homeworks\n"
          ]
        }
      ],
      "source": [
        "#If opening in colab run this cell\n",
        "!git clone https://github.com/CTVisMe/DS4B_Sp24.git\n",
        "%cd DS4B_Sp24/Homeworks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJGEq5z12CPn"
      },
      "source": [
        "**SUBMIT BOTH IPYNB AND PDF VERSIONS OF THE HOMEWORK IN THE FORMAT OF LASTNAME_FIRSTNAME_HW3.IPYNB/PDF**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvaRhyux2CPs"
      },
      "source": [
        "# Predicting Churn\n",
        "\n",
        "After discussing the churn problem at TelCo with Nadia for a while (remember, from HW0?), you've finally defined an adequate target variable for churn and gathered relevant data to predict it. Moreover, the marketing department has come up with an amazing retention offer: the offer is guaranteed to convince customers to extend their contract for an extra year after receiving it. Unfortunately, the offer is quite expensive; it costs $200. __You have enough budget to give the retention offer to up to 25% of the customers whose contracts are expiring.__\n",
        "\n",
        "It is your job to use data from previous contract expirations to build a churn predictive model and make a recommendation of whom to target with the offers. You have assembled the best historical data set you can at this point, which includes:\n",
        "\n",
        "- Gender: Whether the customer is a male or a female\n",
        "- SeniorCitizen: Whether the customer is a senior citizen or not (1, 0)\n",
        "- Partner: Whether the customer has a partner or not (Yes, No)\n",
        "- Dependents: Whether the customer has dependents or not (Yes, No)\n",
        "- Tenure: Number of months the customer has stayed with the company\n",
        "- PhoneService: Whether the customer has a phone service or not (Yes, No)\n",
        "- MultipleLines: Whether the customer has multiple lines or not (Yes, No, No phone service)\n",
        "- InternetService: Customer’s internet service provider (DSL, Fiber optic, No)\n",
        "- OnlineSecurity: Whether the customer has online security or not (Yes, No, No internet service)\n",
        "- OnlineBackup: Whether the customer has online backup or not (Yes, No, No internet service)\n",
        "- DeviceProtection: Whether the customer has device protection or not (Yes, No, No internet service)\n",
        "- TechSupport: Whether the customer has tech support or not (Yes, No, No internet service)\n",
        "- StreamingTV: Whether the customer has streaming TV or not (Yes, No, No internet service)\n",
        "- StreamingMovies: Whether the customer has streaming movies or not (Yes, No, No internet service)\n",
        "- Contract: The contract term of the customer (Month-to-month, One year, Two year)\n",
        "- PaperlessBilling: Whether the customer has paperless billing or not (Yes, No)\n",
        "- PaymentMethod: The customer’s payment method (Electronic check, Mailed check, Bank transfer (automatic), Credit card (automatic))\n",
        "- MonthlyCharges: The amount charged to the customer monthly\n",
        "- Churn: Whether the customer churned or not shortly after contract expiration (Yes or No)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QxorapP2CPt"
      },
      "source": [
        "__1. Load the churn data. The code below will also transform your categorical variables into dummy variables. No points for this. This is just meant to help you get started.__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "fJnv3sWZ2CPt"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# If necessary change the path below so that it points to your file.\n",
        "data_path = \"./data/data-hw3.csv\"\n",
        "\n",
        "df = pd.read_csv(data_path)\n",
        "df = pd.get_dummies(df, drop_first=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmcmkCD-2CPu"
      },
      "source": [
        "__2. Split the data into 80% training data and 20% test data.__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "mx5P6XMn2CPu"
      },
      "outputs": [],
      "source": [
        "# Your code goes here"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "__3. Build the best model you can using a decision tree classifier. Using 10-fold Cross-validation on the TRAINING set, try several values between 10 and 200 for the hyperparameter `min_samples_leaf`.__ You can use a for loop or `GridSearchCV` for this (do not use the TEST data at all for this example).  Report the best value of the parameter `min_samples_leaf` and the AUC associated with it.   "
      ],
      "metadata": {
        "id": "ElShnCURCtbM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SAMPLE CODE for #3\n",
        "# from sklearn.tree import DecisionTreeClassifier\n",
        "# from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# target = \"Churn_Yes\"\n",
        "# predictors = df.columns[df.columns != target]\n",
        "# example_model = DecisionTreeClassifier()\n",
        "# # Remember to only use the training data here!!\n",
        "# avg_auc = cross_val_score(example_model, df[predictors], df[target], cv=10, scoring=\"roc_auc\").mean().round(4)\n",
        "# print(avg_auc)"
      ],
      "metadata": {
        "id": "ALoFhki9CtJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.  Do the same for logistic regression.  Try different values for the hyperparameter C between 10 and 200**\n"
      ],
      "metadata": {
        "id": "XdZA0dGGFTUC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code goes here"
      ],
      "metadata": {
        "id": "H-wWTTKyFXbg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yd1LLyU_2CPv"
      },
      "source": [
        "**5.  Now do a third classification model of your choice. You can use something we learned in class or something else you want to try!  SVM, kNN, NeuralNet, RandomForest etc .  Whatever model you choose -- pick a hyperparameter and try and optimize.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Jnmi64Z2CPv"
      },
      "outputs": [],
      "source": [
        "# Your code goes here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "__6.  Select a \"best\" model based on your three models above, what is it?__  "
      ],
      "metadata": {
        "id": "EeHZQSchGLnm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "f4xmajqV2CPw"
      },
      "outputs": [],
      "source": [
        "# Your code goes here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5QTooX42CPx"
      },
      "source": [
        "__7. Use your TEST  data to plot the ROC Curves for each of the three best models you found in the previous question (make sure to plot the three curves together on the same plot). Would you consider changing your model choice after looking at the curves?__\n",
        "\n",
        "HINT: There are some helpful code hints below, but you will need to edit them with the right arguments!!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2AqOpFxp2CPx"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# #Initiate the models using the best parameters found above\n",
        "\n",
        "# # Call 'fit' on the entire TRAINING data for each model\n",
        "# MY_MODEL.fit(DF_PREDICTORS, DF_TARGET)\n",
        "\n",
        "# # Determine probabilities of churn from the TEST data (using .predict_proba)\n",
        "# probs = MY_MODEL.predict_proba(DF_PREDICTORS)[:, 1]\n",
        "\n",
        "# # Use \"roc_curve\" to get the points for the three curves\n",
        "# fpr, tpr, thresholds = roc_curve(DF_TARGET, probs)\n",
        "\n",
        "\n",
        "# #plot the ROC curves\n",
        "# plt.plot(fpr, tpr)\n",
        "# plt.ylabel(\"True positive rate\")\n",
        "# plt.xlabel(\"False positive rate\")\n",
        "# plt.legend()\n",
        "# plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9MWzvGh2CPy"
      },
      "source": [
        "__8. What are the costs and benefits of this offer?  HINT: Take a look at the description of the data and the retention offer. You can think in terms of averages across all customers.__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZyELyv-2CPy"
      },
      "source": [
        "Put your answer here using Markdown."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_w-SmYsA2CPz"
      },
      "source": [
        "__9. Using your best model along with the costs and benefits, now we want to plot a PROFIT CURVE.  Split your TRAINING data into two sets, one with 90% of the TRAINING data (the \"SUB-TRAINING\" set) and another with 10% of the TRAINING data (the VALIDATION set). Train the model you selected with the \"SUB-TRAINING\" set, apply it to the VALIDATION set, and plot a profit curve by sorting customers according to their probability of churning.   Calculate the profit at each threshold, and show the appropriate plot.  Make a recommendation to Nadia of the appropriate threshold to use - aka how many people to target with the retention incentive according to this profit curve.__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "M415_k9I2CPz"
      },
      "outputs": [],
      "source": [
        "# Your code goes here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXMN7h2s2CP0"
      },
      "source": [
        "__10. Now that you have chosen a model and a threshold, it is time to evaluate the potential impact of your solution on the holdout set. Using the results from your targeting above, how much money do you estimate that your recommendation would have saved as compared to giving the offer to a random set of customers?__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "pYdWCB2U2CP0"
      },
      "outputs": [],
      "source": [
        "# Your code goes here"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "__11.  Is there a better way to rank customers to take advantage of their individual spending - rather than using an average across all customers?  Calculate an individualized expected value for profit/loss for each customer to rank them. Use it to plot a profit curve according to this new ranking.  Do the same comparison against a random set as you did in number 10.  Are the results any better? Would your recommendation change?__"
      ],
      "metadata": {
        "id": "MHKrvIk5L45Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code goes here"
      ],
      "metadata": {
        "id": "oNF_h55mTtaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SUBMIT BOTH IPYNB AND PDF VERSIONS OF THE HOMEWORK IN THE FORMAT OF LASTNAME_FIRSTNAME_HW3.IPYNB/PDF**\n"
      ],
      "metadata": {
        "id": "Oth5r-R1SQhY"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}